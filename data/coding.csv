Date,Focus,Summary,Challenges/Problems,Next Steps,Members,"Media Links / Additional Notes (i.e. GooglePhotos link, video link, etc.)"
10/3/2020 (morning),"Downloading applications and making Github accounts, taking apart last year's robot","We downloaded a lot of software (Android Studio, and other applications to make that work) to help us connect and contribute to the Wildbots GitHub. We looked over the pre-existing drive library to see what we could figure out based on our limited knowledge of the coding language. We also started to take apart RB (rip) so we could use the chassis to start coding the robot.","Some computer problems, when downloading, there were various different errors. Taking the mechs off of last year's robot turned out to be much more complicated than expected, so we still have some work to do on that next week.",Finish unscrewing the robot so that it can be used for learning and practice.,"Liza, Sophia",
10/3/2020 (afternoon),"Downloading Android Studio, making a Github account, and looking at a little bit of old code",We downloaded Android Studio. We were able to create Github accounts and join the Wildbots GitHub. We also looked over the drive library and the driver-controlled code.,We had some problems with Android Studio because there were some new error messages that we weren't sure how to fix.,Finish correcting error messages and work towards a better understanding of the program,"Bonnie, Kate, Abby, Liza",
10/10/2020 (morning),"Getting an intro to Java tutorial, finishing taking apart the past robot, connecting the Driver control Hub","Today we learned the basics of java coding (arrays, void, int, etc.) and took apart last year's robot to have access to the chassis. We later set up the new control hub and connected the phone and then took the driving code from one of last year's code, and learned how to push and pull it.","We had some trouble with pushing and pulling out the drive code and remembering to capitalize ""System"" in the code.",Get this code to work on the robot,"Bonnie, Sophia, Liza",
10/10/2020 (afternoon),"Getting the Teleop mode to work, setting up encoders",Today we used the Teleop mode that the morning group built and got it to work with the control hub. We also started working on the encoders and trying to correspond to the data that they return to distance.,"To test the encoders, we made an autonomous mode that would log the encoder data, move, then log the encoder data again so that we could find the difference, but for some reason, the logs were not showing up in the new autonomous","Finish figuring out encoder data, maybe try to figure out why the logs were not showing up.","Abby B, Kate, Liza",
10/17/2020 (morning),"Learning how to set up the robot correctly, running some code autonomously, tried to use the controllers to drive and turn, learned about strafing","We started by pulling a basic auton code from last year's GitHub and fixed some parts of it so we could then try to transfer the code from our computers to the robot. We also tried twice to connect the controllers and phones to the robot, once with instructions, and once on our own. We then took a break and worked with the building team on how the mechs would work specifically and offered some ideas which when compiled, the building team put the final idea on the whiteboard. Kate then taught us (Liza and Sophia) strafing math and how the mecanum wheels work.","Sometimes, the phone froze or we forgot steps in between when setting up the robot, so we had to restart again.","After learning the concept of strafing, we wanted to try to turn while moving on a diagonal. We also wanted to work with some sensors and make moving on a diagonal more precise. We also proposed a code that (during TeleOp) could sense the side of the goal and hit all three power shots in a row!","Liza, Sophia, Kate",
10/17/2020 (afternoon),Measuring encoder values,"We wanted to make it so that we can correlate encoder values to distance. To do this, Haley and Abby measured approximately 50 data points of varying distances to determine the correlation. Fortunately, there definitely appeared to be a correlation between the values and the distance which means that our encoders are working, however, there was a bit of variation in the exact values of the encoders between identical distances. Liza and Kate then used the values we recorded to plot graphs and try to make some preliminary relations between distance and value.",The front right wheel likes to lift off the ground ~floaty~ and the robot slips a little bit after the coded distance is done,"In upcoming weeks, we need to figure out a method of utilizing these measured encoder values and distances and also figure how the two are actually related, perhaps by making an equation.","Kate, Abby, Liza, Haley",
10/24/2020 (morning),Coding the TeleOp ring shooter,"We wrote code so that when ""B"" was pressed on the second controller, the middle wheel would spin at full speed, and when the button was released, the wheel would stop spinning completely. We also connected a new expansion hub to the chassis we were working on. We also took apart one of last year’s motors and built a new Ultra Planetary Motor that we tested our code on. We then pushed it into GitHub. 
","While writing the code, we had trouble with some errors, especially when figuring out where to put the new code and figuring out that we needed to add ""intake=hardwareMap.get(DcMotor.class, ""in take"");"". We also had a little trouble finding instructions for connecting the expansion hub and building the ultra planetary gearbox. ",We want to make it a switch instead of making the driver continuously press the button. We were thinking of creating a boolean variable and then using it to switch the truth/false value to its opposite every time the button is pressed.,"Bonnie, Liza, Sophia",
10/24/2020 (afternoon),LEDs and Arrays/encoder testing,"We tested the LEDs with a sample code and added them (as servos) into the configuration. We also worked on correlating the encoder values into distance through creating an enum and hashtable for the encoder values. 
","One wheel floats, so it didn’t stop moving when we tried to control the wheels by their encoder values.
",We will attempt to understand the sample code and fix the code so that all the wheels stop moving.,"Abby, Kate, Liza",
10/31/2020 (morning),Begin coding distance sensors for autonomous,We discussed strategies for autonomous based on how many rings we were given during auton. We then joined with the building team to figure out where the intake and launching mechs were going to be on the robot and how we might pick up the wobble goal. We also took two distance sensors and began coding them and connecting them to the phone. We used code from last year to help us since none of us had much experience working with distance sensors. We had to make a few changes for the code to work. We created a mini setup of the field and added tape before we started testing.,"We did not know which bus and which port to connect the sensor to, so we had to test different ones and then try them several times to find the right ones. We eventually figured out that the configuration for the top sensor was 12C Bus 1 Port 0 and the bottom was 12C Bus 2 Port 0. We also didn't realize at first that the robot would be preloaded with 3 rings which meant that some of our strategies had to be revised. We had to take into consideration the size of the robot while we were planning on how to use the distance sensors, and we had to consult with the Building team and finally decided to put them in the front right corner of the robot.",We will code the distance sensors to see how many rings are present (knowing there is a wide range of error between the two sensors).,"Bonnie, Liza, Sophia, Kate",
11/7/2020 (morning),We finished adding distance sensors to the chassis and coding them to detect how many rings are there at the beginning of the autonomous period. We also brainstormed what to do in the various scenarios.,"We cut steel pieces so we could attach the sensors to the robot in a place that would not interfere with the intake and output mechs. The distance sensors are lock-tightened onto the steel sticks. We then went to turn on the robot and phone but it was dead. So, we made a prototype code for how to sense how many distance sensors there were in the stack. We also realized that the number of rings would matter in that the wobble goal would have to be placed on a different tile according to the number of rings. (0 rings - A, 1 ring - B, 4 rings - C). We then pushed the prototype code onto the GitHub (this is not based on actual numbers pulled from the distance sensors but from estimations). 
We also celebrated because Biden won!!","The phone connected to the robot was out of battery, so we were not able to test our code yet. We hope that it will work. When attaching the distance sensors, we had some trouble planning where and how we should attach them on the robot and the screws were sometimes difficult to deal with. Some of the distance sensor parts broke, but we replaced these. The bottom distance sensor is supposed to detect if there is only one ring at the beginning of the autonomous period, but it is too high up and might miss the ring. We considered to angle it down, but then we were afraid it might detect the ground instead. We will try to attach it lower if possible.",Test the code for the distance sensors. Try to improve accuracy when driving to a specific distance. Think about paths for driving to wobble goal boxes.,"Bonnie, Liza, Sophia",
11/7/2020 (afternoon),"We tested the distance sensor code, figured out how to account for outliers in distance sensor values, and used encoders to determine x and y values of the robot.","We tested if the distance sensor prototype code could in fact test whether there were 0, 1, or 4 rings. (which it could). However, we found that the distance sensor (especially the bottom one) would often alternate between displaying ""50"" and ""800"" as values so we started to write out the code on a whiteboard so we could take the average of the values and have fewer errors.",The distance sensors are not exactly reliable so we're going to have to fix the code for that. So many problems with the encoders not working.,"Make the code that averages the dist values. Also, make the encoder value code work.","Abby, Liza",
11/14/2020 (morning),"We finalized the distance sensor ring detection angles, strategized ways to line up with the goal and power shots, and started figuring out how to use the CV webcam.","We tested different angles of the distance sensors to see at which angles they would correctly sense the stack height. We hot glued the distance sensors after we found the angle we wanted. We brainstormed strategy and listed ways to line up to shoot for the high goal. We decided on trying to use a webcam, so we started finding resources and figuring out how to code the webcams.",OpenCV won't load because of a 64 bit problem. USBC needs to be put in with the line up for speed.,Code the CV webcam to use it for distance sensing (by seeing how many pixels a certain object takes up in the image) and for helping the robot line up with the goal or power shot behind the launch line.,"Bonnie, Kate, Liza, Sophia",
11/14/2020 (afternoon),Encoders and Wobble goal,"We worked on getting the robot to move to a specific point on the field, set up the webcam, and laser cut a wobble goal prototype.",We had trouble laser cutting the wobble goal mech and the encoders are being rude.,"Continue with localization, and build the wobble goal mech.","Abby, Liza",
11/21/2020 (morning),Work on camera vision,"We looked at and used the sample code for camera vision to identify the pictures. The code also gave us the x, y, z coordinates of the camera in the field (we had to keep in mind that we were half field). The example code gave us the rotation of the robot as well. We also coded to find the IMU angle.","We realized that the distance sensors need to be close enough to the pictures for it to recognise it, which means that the robot can't initially see the field marker from the other side of the field. We also had some trouble remembering our Vuforia license username and password.","Use the image targets and angle measurments to determine where the robot is on the field, and make the robot go to the right place for shooting and wobble goal parking.","Bonnie, Sophia, Liza, Kate",
11/21/2020 (afternoon),Camera vision auton and teleOp,"We split into two groups to start writing programs for the camera vision using what the morning team had written.  The autonomous is trying to line up in front of the goal from a set starting postition. The teleOp is [yes], we also figured out the placement of the webcam in contrast to the rear left cornor of the chassis","For the auton, we will need to take into account the distance that the cameravision can see the images at. We had trouble figuring out the axis of the field and the angle of the robot.",Encorporate webcam coordinates as constants so that  we can always know the webcam position; get the auton to actually work; continue to work on camera vision and make the programs more robust,"Abby, Liza, Kate","field, and  webcam map (coordinates) "
"12/5/2020 (morning)

","Work on creating an AutonLibrary, brainstorming with encoders","We wanted to create an AutonLibrary that was similar to the DrivingLibrary we had. First, we brainstormed auton paths and determined what functions we wanted in the library and then began writing code. We were able to add the functions that got the stack height of the rings, identified the navigation image targets, and lined up to the goal. At the end, half of us  began to think about encoders and dead wheel odometry.","One challenge we encountered today was figuring out how we wanted to organize the AutonLibrary. We wanted to make sure that it would be helpful in future years as well, so we decided that there would not be too many variables that were only specific to this year's game. We also had some errors in the code that took us a while to fix, but we were able to address all of them. The omni wheels do not fit onto the axle that the encoder does, so we're going to have to engineeer something to get it to fit on the axle (because the omni wheel is the most reccomended wheel for dead wheel odometry and it would reduce friction). We are also concerned however, that they will slip too much; therefore, we are considering using the green squishy wheels becasue they do fit on the axle (which may however cause too much friction when they are dragging although they wouldnt have too much weight pulling them down).",Continue adding to the AutonLibrary (lining up w/power shots). Test the code that has already been written. Maybe think more about wobble goal stuff?  Make an odometry prototype with green wheels and quickly figure out odometry math ,"Bonnie, Liza, Sophia, Kate","Auton Path, and Simple controller for lining up with goal"
"12/5/2020 (afternoon)

","Automatic lining up with the goal, odometry ","We succesfully put two green squishy wheels on one of the chassis. We continued to write the auton library and testing the code in it along the way, specifically we were working on  lining up with goal using vuforia and the sample code we got from a while ago (its been edited since). ",We realized that we were missing alot of vuforia and initialization components so we added them.,"finish the auton library, and code the dead wheels (encoders) and install the third squishy wheel.","Kate, Liza, Kate",
12/12/2020 (morning),Using green squishy wheels to get more accurate encoder values,"We moved the green squishy wheels on the sides of the chassis, so they are across from each other. We then tested the wheels to see if they moved with the robot. They seemed to move consistently with the robot, so we tried to get the encoders to work. The encoders are now printing values.","The robot cannot strafe as the wheels have too much friction. Also, the encoders are returning values that don't exactly make sense. ","We need different wheels, so there is less friction. We need to figure out why the values that the encoders are returning are strange.","Abby, Kate, Liza",
1/23/2021 (morning),Creating a TeleOp mode and parking on the launch line in autonomous mode,"We planned out what we wanted the TeleOp mode to do and decided to code driving using the joysticks, turning the lauching and intake motors on/off, and using a button to line up with the goal.  We also wrote a skeleton code for parking on the line, which should work but we will also have to test whether it moves in the right direction and figure out what times work for moving the robot to the exac spaces. We also thought about what sensors would work best ot optimize that code, and we were considering color sensors, distance sensors, and a camera to recognize lines. ","For creating the Teleop mode, we had some trouble when uploading the code because we did not yet have the intake and launching motors connected to the robot we were using. We also had some errors that took a while to work out, such as when creating an instance of the autonLibrary. The robot is also not moving in the right direction anymore - this could be a wiring or coding problem and we aren't sure.","We want to work on lining up with the goal (because it did not work), install the color sensor or distance sensors, test the parking code and make it work, and optimize autonPark with certain sensors.","Sophia, Bonnie, Liza, Kate",
1/23/2021 (afternoon),Testing time-based parking and working on angle when lining up with goal,We fixed the robot's driving in different angles and also fixed the lining up code. We then tested the times for which  the robot would park on line . We also tried to install the color sensor but alas!!,"The color sensor was too outdated for the code.. oops! Also, the configurations were being tough today. The drive motors were also being difficult- we realized we were using the wrong function. The phone also stopped connecting last minute. ",Order an encoder and a color sensor! Then have a great scrimmage!!,"Kate, Liza",
1/30/2021,scrimmage! and installing sensors,We installed a color sensor and two omniwheels,we had trouble connecting the wheels because we have the control hub and expansion hub placed in an unfortunate spot,next time we will work on odometry and test the color sensor code,"Kate, Liza, Sophia, Bonnie, Abby",
2/6/2021,Testing color sensors,"Installed a color sensor on second robot, worked on writing code and began to test","We had to remove the distance sensors from driving library so they wouldn't be required every time we want to run the robot. We also had to attach a color sensor to our second robot, as building was working with the one that already had one attached.",Continue testing the color sensors,"Liza, Deedee",
2/6/2021,Navigation with Vuforia,We worked on rewriting our Vuforia navigation code to work if we want to launch further back (using the alliance target rather than the goal target),"Even though we used the same code as before, we were having a lot of trouble with the lining up—we're struggling to determine what the problem is because we feel confident in the ideas of this code having seen it work well before","Continue testing Vuforia, but also begin to focus on driver practice so that the drivers could line up on their own consistently if necessary",Kate,
